# Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

- **Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº:** `/home/pavel/projects/content-aggregator-bot`
- **Ğ”Ğ°Ñ‚Ğ°:** Sun Feb  8 03:15:51 MSK 2026
- **Ğ¤Ğ°Ğ¹Ğ»Ğ¾Ğ²:** 21

## Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

```text
.
â”œâ”€â”€ app
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __main__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ database
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ repository.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ content.py
â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ publishers
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ telegram.py
â”‚   â”œâ”€â”€ scrapers
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ factory.py
â”‚   â”‚   â”œâ”€â”€ telegram.py
â”‚   â”‚   â””â”€â”€ vk.py
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â”œâ”€â”€ rate_limiter.py
â”‚       â””â”€â”€ validators.py
â””â”€â”€ pyproject.toml
```

---

## Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²

### app/__init__.py

```python
# app/__init__.py

__version__ = "0.1.0"
__author__ = "FH IT"
__description__ = (
    "Ğ‘Ğ¾Ñ‚ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ¸ Ñ€ĞµĞ¿Ğ¾ÑÑ‚Ğ° ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ğ¸Ğ· Telegram Ğ¸ VK"
)

```

### app/__main__.py

```python
# app/__main__.py

import asyncio

from app.orchestrator import Orchestrator
from app.utils.logger import logger, setup_logger


async def main() -> None:
    setup_logger()

    logger.info("=" * 60)
    logger.info("Ğ—Ğ°Ğ¿ÑƒÑĞº Content Aggregator Bot")
    logger.info("=" * 60)

    orchestrator = Orchestrator()

    try:
        await orchestrator.initialize()
        await orchestrator.run()

    except KeyboardInterrupt:
        logger.info("ĞŸÑ€ĞµÑ€Ğ²Ğ°Ğ½Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼")

    except Exception as e:
        logger.exception(f"ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")
        raise

    finally:
        logger.info("ĞŸÑ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾")


def run_main():
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass


if __name__ == "__main__":
    run_main()

```

### app/config.py

```python
# app/config.py

from pathlib import Path

from pydantic import Field
from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=False,
        extra="ignore",
    )

    telegram_bot_token: str = Field(..., description="Ğ¢Ğ¾ĞºĞµĞ½ Telegram Ğ±Ğ¾Ñ‚Ğ°")
    telegram_target_chat_id: str = Field(
        ..., description="ID Ñ†ĞµĞ»ĞµĞ²Ğ¾Ğ³Ğ¾ Ñ‡Ğ°Ñ‚Ğ° Ğ´Ğ»Ñ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸"
    )

    telegram_api_id: int = Field(..., description="API ID Ğ¸Ğ· my.telegram.org")
    telegram_api_hash: str = Field(..., description="API Hash Ğ¸Ğ· my.telegram.org")
    telegram_session_name: str = Field(
        default="aggregator_session", description="Ğ˜Ğ¼Ñ Ñ„Ğ°Ğ¹Ğ»Ğ° ÑĞµÑÑĞ¸Ğ¸ Telegram"
    )

    vk_access_token: str = Field(..., description="Ğ¢Ğ¾ĞºĞµĞ½ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ° VK API")
    vk_api_version: str = Field(default="5.131", description="Ğ’ĞµÑ€ÑĞ¸Ñ VK API")

    database_url: str = Field(
        default="sqlite+aiosqlite:///./data/aggregator.db",
        description="URL Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
    )

    log_level: str = Field(default="INFO", description="Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ")
    log_file: str = Field(default="logs/bot.log", description="ĞŸÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ Ğ»Ğ¾Ğ³Ğ¾Ğ²")

    scrape_interval_seconds: int = Field(
        default=60, description="Ğ˜Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ» Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°Ğ¼Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ² (ÑĞµĞºÑƒĞ½Ğ´Ñ‹)"
    )
    rate_limit_requests_per_minute: int = Field(
        default=30, description="ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ Ğº API"
    )
    post_check_delay_seconds: int = Field(
        default=600, description="Ğ—Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ¿ĞµÑ€ĞµĞ´ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¾Ğ¹ Ğ¿Ğ¾ÑÑ‚Ğ° (ÑĞµĞºÑƒĞ½Ğ´Ñ‹)"
    )

    sources_config: Path = Field(
        default=Path("config/sources.yaml"),
        description="ĞŸÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ ÑĞ¾ ÑĞ¿Ğ¸ÑĞºĞ¾Ğ¼ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²",
    )

    def ensure_directories(self) -> None:
        log_path = Path(self.log_file)
        log_path.parent.mkdir(parents=True, exist_ok=True)

        if self.database_url.startswith("sqlite"):
            db_path = self.database_url.split("///")[-1]
            Path(db_path).parent.mkdir(parents=True, exist_ok=True)

        self.sources_config.parent.mkdir(parents=True, exist_ok=True)


# ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚ Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² "telegram_bot_token", "telegram_target_chat_id", "telegram_api_id", "telegram_api_hash", "vk_access_token"
settings = Settings()

```

### app/database/__init__.py

```python
# app/database/__init__.py

from app.database.models import Base, ProcessedPost
from app.database.repository import PostRepository

__all__ = ["Base", "ProcessedPost", "PostRepository"]

```

### app/database/models.py

```python
# app/database/models.py

from datetime import datetime

from sqlalchemy import Boolean, DateTime, Integer, String, Text
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column


class Base(DeclarativeBase):
    pass


class ProcessedPost(Base):
    __tablename__ = "processed_posts"

    id: Mapped[int] = mapped_column(Integer, primary_key=True, autoincrement=True)

    platform: Mapped[str] = mapped_column(String(50), nullable=False, index=True)
    source_id: Mapped[str] = mapped_column(String(255), nullable=False, index=True)
    post_id: Mapped[str] = mapped_column(String(255), nullable=False, index=True)

    content_hash: Mapped[str] = mapped_column(
        String(64), nullable=False, unique=True, index=True
    )

    url: Mapped[str] = mapped_column(Text, nullable=False)

    created_at: Mapped[datetime] = mapped_column(DateTime, nullable=False)
    processed_at: Mapped[datetime] = mapped_column(
        DateTime, nullable=False, default=datetime.now
    )

    published: Mapped[bool] = mapped_column(Boolean, nullable=False, default=False)
    published_at: Mapped[datetime | None] = mapped_column(DateTime, nullable=True)
    target_message_id: Mapped[int | None] = mapped_column(Integer, nullable=True)

    error_message: Mapped[str | None] = mapped_column(Text, nullable=True)

    def __repr__(self) -> str:
        """Ğ¡Ñ‚Ñ€Ğ¾ĞºĞ¾Ğ²Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸."""
        return (
            f"<ProcessedPost(id={self.id}, "
            f"platform={self.platform}, "
            f"post_id={self.post_id}, "
            f"published={self.published})>"
        )

```

### app/database/repository.py

```python
# app/database/repository.py

"""Ğ¡Ğ»Ğ¾Ğ¹ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ° Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼ (Repository Pattern)."""

from datetime import datetime

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker, create_async_engine

from app.database.models import Base, ProcessedPost
from app.models.content import Post
from app.utils.logger import logger


class PostRepository:
    def __init__(self, database_url: str):
        self.engine = create_async_engine(database_url, echo=False)
        self.session_factory = async_sessionmaker(
            self.engine, class_=AsyncSession, expire_on_commit=False
        )
        logger.debug(f"Ğ ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½: {database_url}")

    async def init_db(self) -> None:
        async with self.engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
        logger.info("Ğ‘Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°")

    async def is_post_processed(self, content_hash: str) -> bool:
        async with self.session_factory() as session:
            result = await session.execute(
                select(ProcessedPost).where(ProcessedPost.content_hash == content_hash)
            )
            return result.scalar_one_or_none() is not None

    async def mark_post_processed(self, post: Post) -> ProcessedPost:
        async with self.session_factory() as session:
            db_post = ProcessedPost(
                platform=post.platform.value,
                source_id=post.source_id,
                post_id=post.post_id,
                content_hash=post.content_hash,
                url=post.url,
                created_at=post.created_at,
                processed_at=datetime.now(),
                published=False,
            )
            session.add(db_post)
            await session.commit()
            await session.refresh(db_post)

            logger.debug(
                f"ĞŸĞ¾ÑÑ‚ Ğ¿Ğ¾Ğ¼ĞµÑ‡ĞµĞ½ ĞºĞ°Ğº Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹: {post.platform}:{post.post_id}"
            )
            return db_post

    async def mark_post_published(
        self, content_hash: str, target_message_id: int | None = None
    ) -> None:
        async with self.session_factory() as session:
            result = await session.execute(
                select(ProcessedPost).where(ProcessedPost.content_hash == content_hash)
            )
            db_post = result.scalar_one_or_none()

            if db_post:
                db_post.published = True
                db_post.published_at = datetime.now()
                db_post.target_message_id = target_message_id
                await session.commit()
                logger.debug(f"ĞŸĞ¾ÑÑ‚ Ğ¿Ğ¾Ğ¼ĞµÑ‡ĞµĞ½ ĞºĞ°Ğº Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹: {content_hash[:16]}...")

    async def mark_post_failed(self, content_hash: str, error_message: str) -> None:
        async with self.session_factory() as session:
            result = await session.execute(
                select(ProcessedPost).where(ProcessedPost.content_hash == content_hash)
            )
            db_post = result.scalar_one_or_none()

            if db_post:
                db_post.published = False
                db_post.error_message = error_message
                await session.commit()
                logger.warning(
                    f"ĞŸĞ¾ÑÑ‚ Ğ¿Ğ¾Ğ¼ĞµÑ‡ĞµĞ½ ĞºĞ°Ğº Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹: {content_hash[:16]}... - {error_message}"
                )

    async def get_post_by_hash(self, content_hash: str) -> ProcessedPost | None:
        async with self.session_factory() as session:
            result = await session.execute(
                select(ProcessedPost).where(ProcessedPost.content_hash == content_hash)
            )
            return result.scalar_one_or_none()

    async def get_unpublished_posts(self, limit: int = 100) -> list[ProcessedPost]:
        async with self.session_factory() as session:
            result = await session.execute(
                select(ProcessedPost)
                # Avoid equality comparisons to `False`; use `not ProcessedPost.published:` for false checks
                .where(ProcessedPost.published == False)
                .where(ProcessedPost.error_message.is_(None))
                .order_by(ProcessedPost.created_at)
                .limit(limit)
            )
            return list(result.scalars().all())

    async def close(self) -> None:
        await self.engine.dispose()
        logger.debug("Ğ¡Ğ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ñ Ğ‘Ğ” Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¾")

```

### app/models/__init__.py

```python
# app/models/__init__.py

from app.models.content import Media, MediaType, PlatformType, Post, PublishedPost

__all__ = ["Media", "MediaType", "PlatformType", "Post", "PublishedPost"]

```

### app/models/content.py

```python
# app/models/content.py

from datetime import datetime
from enum import Enum

from pydantic import BaseModel, Field


class PlatformType(str, Enum):
    TELEGRAM = "telegram"
    VK = "vk"


class MediaType(str, Enum):
    PHOTO = "photo"
    VIDEO = "video"
    DOCUMENT = "document"
    AUDIO = "audio"


class Media(BaseModel):
    type: MediaType
    url: str | None = None
    file_id: str | None = None
    width: int | None = None
    height: int | None = None
    duration: int | None = None
    mime_type: str | None = None


class Post(BaseModel):
    platform: PlatformType
    source_id: str = Field(..., description="ID Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ° (ĞºĞ°Ğ½Ğ°Ğ», Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°)")
    post_id: str = Field(..., description="Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ID Ğ¿Ğ¾ÑÑ‚Ğ° Ğ½Ğ° Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğµ")

    text: str | None = None
    media: list[Media] = Field(default_factory=list)
    url: str = Field(..., description="Ğ¡ÑÑ‹Ğ»ĞºĞ° Ğ½Ğ° Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾ÑÑ‚")

    author: str | None = None
    created_at: datetime = Field(default_factory=datetime.now)
    views: int | None = None

    content_hash: str = Field(..., description="Ğ¥ĞµÑˆ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ğ´Ğ»Ñ Ğ´ĞµĞ´ÑƒĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸")

    class Config:
        use_enum_values = True

    def __str__(self) -> str:
        preview = (
            (self.text[:50] + "...") if self.text and len(self.text) > 50 else self.text
        )
        return f"Post({self.platform}:{self.post_id}, text={preview})"

    def __repr__(self) -> str:
        return self.__str__()


class PublishedPost(BaseModel):
    original_post: Post
    published_at: datetime = Field(default_factory=datetime.now)
    target_message_id: int | None = None
    success: bool = True
    error_message: str | None = None

```

### app/orchestrator.py

```python
# app/orchestrator.py

import asyncio
from datetime import datetime, timezone
from pathlib import Path
import yaml

from app.config import settings
from app.database import PostRepository
from app.models.content import Post
from app.publishers.telegram import TelegramPublisher
from app.scrapers import BaseScraper, ScraperFactory
from app.utils.logger import logger


class SourceConfig:
    def __init__(self, type: str, url: str, enabled: bool = True):
        self.type = type
        self.url = url
        self.enabled = enabled

    def __repr__(self) -> str:
        status = "âœ“" if self.enabled else "âœ—"
        return f"SourceConfig({status} {self.type}: {self.url})"


class Orchestrator:
    def __init__(self):
        self.repository = PostRepository(settings.database_url)
        self.publisher = TelegramPublisher()
        self.scrapers: list[BaseScraper] = []
        self.running = False
        self.start_time = datetime.now(timezone.utc)

    async def initialize(self) -> None:
        logger.info("Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ°...")
        settings.ensure_directories()
        await self.repository.init_db()
        await self.publisher.initialize()
        await self._load_sources()
        logger.info(
            f"ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€ Ğ³Ğ¾Ñ‚Ğ¾Ğ². Ğ ĞµĞ¶Ğ¸Ğ¼: Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ¾ÑÑ‚Ñ‹ Ğ½Ğ¾Ğ²ĞµĞµ {self.start_time.strftime('%H:%M:%S')}"
        )

    async def _load_sources(self) -> None:
        config_path = settings.sources_config
        if not config_path.exists():
            self._create_example_config(config_path)
            return

        try:
            with open(config_path, "r", encoding="utf-8") as f:
                config = yaml.safe_load(f)

            for source_data in config.get("sources", []):
                source = SourceConfig(
                    type=source_data.get("type", ""),
                    url=source_data.get("url", ""),
                    enabled=source_data.get("enabled", True),
                )
                if not source.enabled:
                    continue

                try:
                    scraper = ScraperFactory.create_scraper(source.type, source.url)
                    self.scrapers.append(scraper)
                except ValueError as e:
                    logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ° {source.url}: {e}")

        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ°: {e}")

    def _create_example_config(self, path: Path) -> None:
        pass

    async def run(self) -> None:
        if not self.scrapers:
            logger.error("ĞĞµÑ‚ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²!")
            return

        self.running = True
        logger.info("Ğ—Ğ°Ğ¿ÑƒÑĞº Ñ†Ğ¸ĞºĞ»Ğ°...")

        try:
            while self.running:
                await self._scrape_and_publish_cycle()
                logger.info(f"ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ {settings.scrape_interval_seconds}s...")
                await asyncio.sleep(settings.scrape_interval_seconds)
        except KeyboardInterrupt:
            self.running = False
        finally:
            await self.shutdown()

    async def _scrape_and_publish_cycle(self) -> None:
        logger.info("=== Ğ¡Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ===")

        scrape_tasks = [
            scraper.scrape(limit=1, since_time=self.start_time)
            for scraper in self.scrapers
        ]
        results = await asyncio.gather(*scrape_tasks, return_exceptions=True)

        all_posts: list[Post] = []
        for res in results:
            if isinstance(res, list):
                all_posts.extend(res)

        logger.info(f"ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ²: {len(all_posts)}")

        new_count = 0
        published_count = 0
        skipped_old_count = 0

        for post in all_posts:
            if await self.repository.is_post_processed(post.content_hash):
                continue

            await self.repository.mark_post_processed(post)
            new_count += 1

            post_date = post.created_at
            if post_date.tzinfo is None:
                post_date = post_date.replace(tzinfo=timezone.utc)

            if post_date < self.start_time:
                logger.debug(f"ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½ ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾ÑÑ‚: {post.url} ({post_date})")
                skipped_old_count += 1
                continue

            logger.info(
                f"ĞĞĞ’Ğ«Ğ™ ĞŸĞĞ¡Ğ¢: {post.url}. ĞŸÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· {settings.post_check_delay_seconds}Ñ..."
            )
            await asyncio.sleep(settings.post_check_delay_seconds)

            try:
                msg_id = await self.publisher.publish_post(post)
                await self.repository.mark_post_published(post.content_hash, msg_id)
                published_count += 1
                logger.success(f"ĞĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ¾: {post.url}")
            except Exception as e:
                await self.repository.mark_post_failed(post.content_hash, str(e))
                logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ {post.url}: {e}")

        logger.info(
            f"Ğ˜Ñ‚Ğ¾Ğ³ Ñ†Ğ¸ĞºĞ»Ğ°: ĞĞ¾Ğ²Ñ‹Ñ… Ğ² Ğ±Ğ°Ğ·Ğµ={new_count}, ĞĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ¾={published_count}, ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ ÑÑ‚Ğ°Ñ€Ñ‹Ñ…={skipped_old_count}"
        )

    async def shutdown(self) -> None:
        logger.info("Ğ’Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ...")
        for s in self.scrapers:
            await s.close()
        await self.publisher.close()
        await self.repository.close()

```

### app/publishers/__init__.py

```python
# app/publishers/__init__.py

from app.publishers.telegram import TelegramPublisher

__all__ = ["TelegramPublisher"]

```

### app/publishers/telegram.py

```python
# app/publishers/telegram.py

import os
import asyncio
from datetime import datetime
from aiogram import Bot
from aiogram.types import InputMediaPhoto, InputMediaVideo, FSInputFile
from aiogram.exceptions import TelegramRetryAfter
from app.config import settings
from app.models.content import Post, MediaType
from app.utils.logger import logger


class TelegramPublisher:
    def __init__(self):
        self.bot: Bot | None = None
        self.target_chat_id = settings.telegram_target_chat_id

    async def initialize(self) -> None:
        self.bot = Bot(token=settings.telegram_bot_token)
        logger.info("ĞŸÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ğ³Ğ¾Ñ‚Ğ¾Ğ²")

    def _get_input_file(self, media_url: str):
        if os.path.exists(media_url):
            return FSInputFile(media_url)
        return media_url

    def _prepare_caption(self, post: Post) -> str:
        text = post.text or ""
        date_str = post.created_at.strftime("%d.%m.%Y %H:%M")
        footer = f"\n\nğŸ“… {date_str}\nğŸ”— {post.url}"
        max_text_len = 1024 - len(footer) - 5

        if len(text) > max_text_len:
            text = text[:max_text_len] + "..."

        return text + footer

    async def publish_post(self, post: Post) -> int | None:
        if not self.bot:
            raise RuntimeError("ĞŸÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ğ½Ğµ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")

        try:
            final_caption = self._prepare_caption(post)

            if not post.media:
                msg = await self.bot.send_message(
                    self.target_chat_id,
                    text=final_caption,
                    disable_web_page_preview=True,  # Ğ§Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğµ Ğ±Ñ‹Ğ»Ğ¾ Ğ¿Ñ€ĞµĞ²ÑŒÑ ÑÑÑ‹Ğ»ĞºĞ¸-Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°
                )
                return msg.message_id

            if len(post.media) == 1:
                m = post.media[0]
                # ĞÑ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚ Ñ‚Ğ¸Ğ¿Ğ° "str | None" Ğ½ĞµĞ»ÑŒĞ·Ñ Ğ¿Ñ€Ğ¸ÑĞ²Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñƒ "media_url" Ñ‚Ğ¸Ğ¿Ğ° "str" Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ "_get_input_file"
                #   "str | None" Ñ‚Ğ¸Ğ¿Ğ° Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ Ñ‚Ğ¸Ğ¿ "str"
                #       "None" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "str"
                file = self._get_input_file(m.url)

                if m.type == MediaType.PHOTO:
                    msg = await self.bot.send_photo(
                        self.target_chat_id, photo=file, caption=final_caption
                    )
                elif m.type == MediaType.VIDEO:
                    msg = await self.bot.send_video(
                        self.target_chat_id, video=file, caption=final_caption
                    )
                else:
                    msg = await self.bot.send_document(
                        self.target_chat_id, document=file, caption=final_caption
                    )
                return msg.message_id

            else:
                media_group = []
                for i, m in enumerate(post.media[:10]):
                    # ĞÑ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚ Ñ‚Ğ¸Ğ¿Ğ° "str | None" Ğ½ĞµĞ»ÑŒĞ·Ñ Ğ¿Ñ€Ğ¸ÑĞ²Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñƒ "media_url" Ñ‚Ğ¸Ğ¿Ğ° "str" Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ "_get_input_file"
                    #   "str | None" Ñ‚Ğ¸Ğ¿Ğ° Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ Ñ‚Ğ¸Ğ¿ "str"
                    #       "None" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "str"
                    file = self._get_input_file(m.url)
                    cap = final_caption if i == 0 else None

                    if m.type == MediaType.PHOTO:
                        media_group.append(InputMediaPhoto(media=file, caption=cap))
                    elif m.type == MediaType.VIDEO:
                        media_group.append(InputMediaVideo(media=file, caption=cap))

                msgs = await self.bot.send_media_group(
                    self.target_chat_id, media=media_group
                )
                return msgs[0].message_id

        except TelegramRetryAfter as e:
            logger.warning(f"Flood limit. Ğ–Ğ´ĞµĞ¼ {e.retry_after}Ñ")
            await asyncio.sleep(e.retry_after)
            return await self.publish_post(post)
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸: {e}")
            raise

    async def close(self) -> None:
        if self.bot:
            await self.bot.session.close()

```

### app/scrapers/__init__.py

```python
# app/scrapers/__init__.py

from app.scrapers.base import BaseScraper
from app.scrapers.factory import ScraperFactory
from app.scrapers.telegram import TelegramScraper
from app.scrapers.vk import VKScraper

__all__ = ["BaseScraper", "ScraperFactory", "TelegramScraper", "VKScraper"]

```

### app/scrapers/base.py

```python
# app/scrapers/base.py

from abc import ABC, abstractmethod
from datetime import datetime
from app.models.content import Post
from app.utils.logger import logger
from app.utils.rate_limiter import AdaptiveRateLimiter


class BaseScraper(ABC):
    def __init__(
        self, source_url: str, rate_limiter: AdaptiveRateLimiter | None = None
    ):
        self.source_url = source_url
        self.rate_limiter = rate_limiter or AdaptiveRateLimiter(
            max_requests=30, time_window=60
        )
        self._initialized = False

    @abstractmethod
    async def initialize(self) -> None:
        pass

    @abstractmethod
    async def fetch_recent_posts(
        self, limit: int = 10, since_time: datetime | None = None
    ) -> list[Post]:
        pass

    @abstractmethod
    async def close(self) -> None:
        pass

    async def scrape(
        self, limit: int = 10, since_time: datetime | None = None
    ) -> list[Post]:
        try:
            if not self._initialized:
                await self.initialize()
                self._initialized = True

            posts = await self.fetch_recent_posts(limit, since_time)
            await self.rate_limiter.reset_errors()
            return posts

        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ ÑĞ±Ğ¾Ñ€Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· {self.source_url}: {e}")
            await self.rate_limiter.handle_error(e)
            return []

```

### app/scrapers/factory.py

```python
# app/scrapers/factory.py

from app.models.content import PlatformType
from app.scrapers.base import BaseScraper
from app.scrapers.telegram import TelegramScraper
from app.scrapers.vk import VKScraper
from app.utils.logger import logger
from app.utils.validators import validate_telegram_url, validate_vk_url


class ScraperFactory:
    @staticmethod
    def create_scraper(platform: str, source_url: str) -> BaseScraper:
        platform = platform.lower()

        if platform == PlatformType.TELEGRAM.value:
            if not validate_telegram_url(source_url):
                raise ValueError(f"ĞĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Telegram URL: {source_url}")
            logger.debug(f"Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ Telegram ÑĞºÑ€Ğ°Ğ¿ĞµÑ€ Ğ´Ğ»Ñ {source_url}")
            return TelegramScraper(source_url)

        elif platform == PlatformType.VK.value:
            if not validate_vk_url(source_url):
                raise ValueError(f"ĞĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ VK URL: {source_url}")
            logger.debug(f"Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ VK ÑĞºÑ€Ğ°Ğ¿ĞµÑ€ Ğ´Ğ»Ñ {source_url}")
            return VKScraper(source_url)

        else:
            raise ValueError(
                f"ĞĞµĞ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ğ°Ñ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ°: {platform}. "
                f"Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ: {[p.value for p in PlatformType]}"
            )

    @staticmethod
    def auto_detect_platform(source_url: str) -> str | None:
        if validate_telegram_url(source_url):
            return PlatformType.TELEGRAM.value

        if validate_vk_url(source_url):
            return PlatformType.VK.value

        return None

```

### app/scrapers/telegram.py

```python
# app/scrapers/telegram.py

import os
import asyncio
from datetime import datetime, timezone
from telethon import TelegramClient
from telethon.tl.types import Message, MessageMediaPhoto
from app.config import settings
from app.models.content import Media, MediaType, PlatformType, Post
from app.scrapers.base import BaseScraper
from app.utils.logger import logger
from app.utils.validators import (
    extract_telegram_username,
    generate_content_hash,
    sanitize_text,
)

_init_lock = asyncio.Lock()


class TelegramScraper(BaseScraper):
    _shared_client: TelegramClient | None = None

    def __init__(self, source_url: str):
        super().__init__(source_url)
        self.username = extract_telegram_username(source_url)
        self.temp_dir = "data/temp"
        os.makedirs(self.temp_dir, exist_ok=True)

    async def initialize(self) -> None:
        async with _init_lock:
            if TelegramScraper._shared_client is None:
                client = TelegramClient(
                    settings.telegram_session_name,
                    settings.telegram_api_id,
                    settings.telegram_api_hash,
                    # ĞÑ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚ Ñ‚Ğ¸Ğ¿Ğ° "None" Ğ½ĞµĞ»ÑŒĞ·Ñ Ğ¿Ñ€Ğ¸ÑĞ²Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñƒ "connection_retries" Ñ‚Ğ¸Ğ¿Ğ° "int" Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ "__init__"
                    #   "None" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "int"
                    connection_retries=None,
                )
                # "TelegramClient" Ğ½Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ awaitable
                #   "TelegramClient" Ğ½ĞµÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼ Ñ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğ¾Ğ¼ "Awaitable[_T_co@Awaitable]"
                #       "__await__" Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚.
                await client.start()
                TelegramScraper._shared_client = client
                logger.success("ĞĞ±Ñ‰Ğ¸Ğ¹ Telegram ĞºĞ»Ğ¸ĞµĞ½Ñ‚ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½")
            self.client = TelegramScraper._shared_client

    async def _ensure_connected(self):
        if not self.client:
            await self.initialize()
        if not self.client.is_connected():
            try:
                await self.client.connect()
            except Exception:
                pass

    async def fetch_recent_posts(
        self, limit: int = 10, since_time: datetime | None = None
    ) -> list[Post]:
        await self._ensure_connected()
        posts = []
        try:
            # ĞÑ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚ Ñ‚Ğ¸Ğ¿Ğ° "str | None" Ğ½ĞµĞ»ÑŒĞ·Ñ Ğ¿Ñ€Ğ¸ÑĞ²Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñƒ "entity" Ñ‚Ğ¸Ğ¿Ğ° "EntitiesLike" Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ "get_entity"
            #   "str | None" Ñ‚Ğ¸Ğ¿Ğ° Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ Ñ‚Ğ¸Ğ¿ "EntitiesLike"
            #       "None" Ñ‚Ğ¸Ğ¿Ğ° Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ Ñ‚Ğ¸Ğ¿ "EntitiesLike"
            #       "None" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "str"
            # Â Â Â Â Â Â "None" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "int"
            # Â Â Â Â Â Â "None" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "PeerUser"
            # Â Â Â Â Â Â "None" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "PeerChat"
            # Â Â Â Â Â Â "None" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "PeerChannel"
            # Â Â Â Â Â Â "None" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "InputPeerEmpty"
            #   ...
            entity = await self.client.get_entity(self.username)
            # ĞÑ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚ Ñ‚Ğ¸Ğ¿Ğ° "Entity | List[Entity]" Ğ½ĞµĞ»ÑŒĞ·Ñ Ğ¿Ñ€Ğ¸ÑĞ²Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñƒ "entity" Ñ‚Ğ¸Ğ¿Ğ° "EntityLike" Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ "iter_messages"
            #   "Entity | List[Entity]" Ñ‚Ğ¸Ğ¿Ğ° Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ Ñ‚Ğ¸Ğ¿ "EntityLike"
            #       "List[Entity]" Ñ‚Ğ¸Ğ¿Ğ° Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ Ñ‚Ğ¸Ğ¿ "EntityLike"
            # Â Â Â Â Â Â "List[Entity]" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "str"
            # Â Â Â Â Â Â "List[Entity]" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "int"
            # Â Â Â Â Â Â "List[Entity]" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "PeerUser"
            # Â Â Â Â Â Â "List[Entity]" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "PeerChat"
            # Â Â Â Â Â Â "List[Entity]" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "PeerChannel"
            # Â Â Â Â Â Â "List[Entity]" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "InputPeerEmpty"
            #   ...
            async for message in self.client.iter_messages(entity, limit=limit):
                if not isinstance(message, Message):
                    continue

                # === ĞĞŸĞ¢Ğ˜ĞœĞ˜Ğ—ĞĞ¦Ğ˜Ğ¯ ===
                # Ğ•ÑĞ»Ğ¸ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ½ since_time, Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ´Ğ°Ñ‚Ñƒ Ğ¡Ğ ĞĞ—Ğ£
                if since_time:
                    msg_date = message.date
                    # "tzinfo" Ğ½Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¼ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ¾Ğ¼ "None"
                    if msg_date.tzinfo is None:
                        # "replace" Ğ½Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¼ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ¾Ğ¼ "None"
                        msg_date = msg_date.replace(tzinfo=timezone.utc)

                    # ĞĞ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ "<" Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ Ğ´Ğ»Ñ "None"
                    if msg_date < since_time:
                        break

                post = await self._parse_message(message)
                if post:
                    posts.append(post)

        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ±Ğ¾Ñ€Ğ° {self.username}: {e}")
        return posts

    async def _parse_message(self, message: Message) -> Post | None:
        try:
            text = sanitize_text(message.message)
            media_list = []

            if message.media:
                try:
                    file_path = await asyncio.wait_for(
                        # ĞĞµ ÑƒĞ´Ğ°ĞµÑ‚ÑÑ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ñƒ "download_media" Ğ´Ğ»Ñ ĞºĞ»Ğ°ÑÑĞ° "Message"
                        #   ĞÑ‚Ñ€Ğ¸Ğ±ÑƒÑ‚ "download_media" Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚ĞµĞ½
                        message.download_media(file=self.temp_dir + "/"),
                        timeout=30.0,
                    )
                    if file_path:
                        m_type = MediaType.DOCUMENT
                        if isinstance(message.media, MessageMediaPhoto):
                            m_type = MediaType.PHOTO
                        elif (
                            hasattr(message.media, "document")
                            # ĞĞµ ÑƒĞ´Ğ°ĞµÑ‚ÑÑ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ñƒ "document" Ğ´Ğ»Ñ ĞºĞ»Ğ°ÑÑĞ° "MessageMedia*"
                            #   ĞÑ‚Ñ€Ğ¸Ğ±ÑƒÑ‚ "document" Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚ĞµĞ½
                            and message.media.document
                            # ĞĞµ ÑƒĞ´Ğ°ĞµÑ‚ÑÑ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ñƒ "document" Ğ´Ğ»Ñ ĞºĞ»Ğ°ÑÑĞ° "MessageMedia*"
                            #   ĞÑ‚Ñ€Ğ¸Ğ±ÑƒÑ‚ "document" Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚ĞµĞ½
                            # ĞĞµ ÑƒĞ´Ğ°ĞµÑ‚ÑÑ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ñƒ "mime_type" Ğ´Ğ»Ñ ĞºĞ»Ğ°ÑÑĞ° "DocumentEmpty"
                            #   ĞÑ‚Ñ€Ğ¸Ğ±ÑƒÑ‚ "mime_type" Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚ĞµĞ½
                            and message.media.document.mime_type.startswith("video")
                        ):
                            m_type = MediaType.VIDEO

                        media_list.append(
                            Media(type=m_type, url=os.path.abspath(file_path))
                        )
                except asyncio.TimeoutError:
                    pass
                except Exception:
                    pass

            if not text and not media_list:
                return None

            content_hash = generate_content_hash(text, [m.url for m in media_list])
            return Post(
                platform=PlatformType.TELEGRAM,
                # ĞÑ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚ Ñ‚Ğ¸Ğ¿Ğ° "str | None" Ğ½ĞµĞ»ÑŒĞ·Ñ Ğ¿Ñ€Ğ¸ÑĞ²Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñƒ "source_id" Ñ‚Ğ¸Ğ¿Ğ° "str" Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ "__init__"
                #   "str | None" Ñ‚Ğ¸Ğ¿Ğ° Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ Ñ‚Ğ¸Ğ¿ "str"
                #       "None" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "str"
                source_id=self.username,
                post_id=str(message.id),
                text=text,
                media=media_list,
                url=f"https://t.me/{self.username}/{message.id}",
                # ĞÑ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚ Ñ‚Ğ¸Ğ¿Ğ° "datetime | None" Ğ½ĞµĞ»ÑŒĞ·Ñ Ğ¿Ñ€Ğ¸ÑĞ²Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñƒ "created_at" Ñ‚Ğ¸Ğ¿Ğ° "datetime" Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ "__init__"
                #   "datetime | None" Ñ‚Ğ¸Ğ¿Ğ° Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ Ñ‚Ğ¸Ğ¿ "datetime"
                #       "None" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "datetime"
                created_at=message.date,
                content_hash=content_hash,
            )
        except Exception:
            return None

    async def close(self):
        pass

```

### app/scrapers/vk.py

```python
# app/scrapers/vk.py

from datetime import datetime, timezone
import vk_api
from app.config import settings
from app.models.content import Media, MediaType, PlatformType, Post
from app.scrapers.base import BaseScraper
from app.utils.logger import logger
from app.utils.validators import extract_vk_id, generate_content_hash, sanitize_text


class VKScraper(BaseScraper):
    def __init__(self, source_url: str):
        super().__init__(source_url)
        self.group_id = extract_vk_id(source_url)
        self.vk_session = None
        self.vk = None

    async def initialize(self) -> None:
        try:
            self.vk_session = vk_api.VkApi(token=settings.vk_access_token)
            self.vk = self.vk_session.get_api()
            logger.info(f"VK API Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ´Ğ»Ñ {self.group_id}")
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° VK API: {e}")

    async def fetch_recent_posts(
        self, limit: int = 10, since_time: datetime | None = None
    ) -> list[Post]:
        if not self.vk:
            await self.initialize()
        posts = []
        try:
            # "wall" Ğ½Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¼ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ¾Ğ¼ "None"
            response = self.vk.wall.get(
                domain=self.group_id,
                count=limit,
                filter="owner",
                v=settings.vk_api_version,
            )
            items = response.get("items", [])

            for item in items:
                if since_time:
                    timestamp = item.get("date", 0)
                    post_date = datetime.fromtimestamp(timestamp, tz=timezone.utc)
                    if post_date < since_time:
                        continue

                post = self._parse_post(item)
                if post:
                    posts.append(post)

        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ±Ğ¾Ñ€Ğ° VK {self.group_id}: {e}")
        return posts

    def _parse_post(self, item: dict) -> Post | None:
        try:
            post_id = str(item.get("id"))
            owner_id = item.get("owner_id")
            text = sanitize_text(item.get("text"))
            media_list = []
            for attachment in item.get("attachments", []):
                att_type = attachment.get("type")
                if att_type == "photo":
                    sizes = attachment.get("photo", {}).get("sizes", [])
                    if sizes:
                        largest = max(sizes, key=lambda x: x.get("width", 0))
                        media_list.append(
                            Media(type=MediaType.PHOTO, url=largest.get("url"))
                        )
                elif att_type == "video":  # Ğ’Ğ¸Ğ´ĞµĞ¾ Ğ² VK ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾Ğµ, Ğ½ÑƒĞ¶Ğ½Ğ° ÑÑÑ‹Ğ»ĞºĞ° Ğ½Ğ° Ğ¿Ğ»ĞµĞµÑ€
                    # Ğ£Ğ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°
                    pass

            if not text and not media_list:
                return None

            timestamp = item.get("date", 0)
            created_at = datetime.fromtimestamp(timestamp, tz=timezone.utc)

            url = f"https://vk.com/wall{owner_id}_{post_id}"
            content_hash = generate_content_hash(
                text, [m.url for m in media_list if m.url]
            )

            return Post(
                platform=PlatformType.VK,
                # ĞÑ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚ Ñ‚Ğ¸Ğ¿Ğ° "str | None" Ğ½ĞµĞ»ÑŒĞ·Ñ Ğ¿Ñ€Ğ¸ÑĞ²Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñƒ "source_id" Ñ‚Ğ¸Ğ¿Ğ° "str" Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ "__init__"
                #   "str | None" Ñ‚Ğ¸Ğ¿Ğ° Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ Ñ‚Ğ¸Ğ¿ "str"
                #       "None" Ğ½ĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ÑŒ "str"
                source_id=self.group_id,
                post_id=post_id,
                text=text,
                media=media_list,
                url=url,
                created_at=created_at,
                content_hash=content_hash,
            )
        # Do not use bare `except`
        except:
            return None

    async def close(self) -> None:
        pass

```

### app/utils/__init__.py

```python
# app/utils/__init__.py

from app.utils.logger import logger, setup_logger
from app.utils.rate_limiter import AdaptiveRateLimiter, RateLimiter
from app.utils.validators import (
    extract_telegram_username,
    extract_vk_id,
    generate_content_hash,
    sanitize_text,
    validate_telegram_url,
    validate_vk_url,
)

__all__ = [
    "logger",
    "setup_logger",
    "RateLimiter",
    "AdaptiveRateLimiter",
    "validate_telegram_url",
    "validate_vk_url",
    "extract_telegram_username",
    "extract_vk_id",
    "generate_content_hash",
    "sanitize_text",
]

```

### app/utils/logger.py

```python
# app/utils/logger.py

import sys

from loguru import logger

from app.config import settings


def setup_logger() -> None:
    logger.remove()

    console_format = (
        "<green>{time:YYYY-MM-DD HH:mm:ss}</green> | "
        "<level>{level: <8}</level> | "
        "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> | "
        "<level>{message}</level>"
    )

    file_format = (
        "{time:YYYY-MM-DD HH:mm:ss.SSS} | "
        "{level: <8} | "
        "{name}:{function}:{line} | "
        "{message}"
    )

    logger.add(
        sys.stderr,
        format=console_format,
        level=settings.log_level,
        colorize=True,
        backtrace=True,
        diagnose=True,
    )

    logger.add(
        settings.log_file,
        format=file_format,
        level=settings.log_level,
        rotation="10 MB",
        retention="1 week",
        compression="zip",
        backtrace=True,
        diagnose=True,
        encoding="utf-8",
    )

    logger.info("Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°")
    logger.debug(f"Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ: {settings.log_level}")
    logger.debug(f"Ğ¤Ğ°Ğ¹Ğ» Ğ»Ğ¾Ğ³Ğ¾Ğ²: {settings.log_file}")


__all__ = ["logger", "setup_logger"]

```

### app/utils/rate_limiter.py

```python
# app/utils/rate_limiter.py

import asyncio
import time
from collections import deque
from functools import wraps

from app.utils.logger import logger


class RateLimiter:
    def __init__(self, max_requests: int, time_window: int = 60):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests: deque[float] = deque()
        self._lock = asyncio.Lock()

    async def acquire(self) -> None:
        async with self._lock:
            now = time.time()

            while self.requests and self.requests[0] < now - self.time_window:
                self.requests.popleft()

            if len(self.requests) >= self.max_requests:
                sleep_time = self.time_window - (now - self.requests[0])
                if sleep_time > 0:
                    logger.debug(f"Rate limit Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ÑƒÑ‚. ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ {sleep_time:.1f}s")
                    await asyncio.sleep(sleep_time)
                    await self.acquire()
                    return

            self.requests.append(now)

    def __call__(self, func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            await self.acquire()
            return await func(*args, **kwargs)

        return wrapper


class AdaptiveRateLimiter(RateLimiter):
    def __init__(
        self,
        max_requests: int,
        time_window: int = 60,
        max_retries: int = 5,
        base_delay: float = 1.0,
    ):
        super().__init__(max_requests, time_window)
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.consecutive_errors = 0

    async def handle_error(self, error: Exception) -> None:
        self.consecutive_errors += 1

        if self.consecutive_errors > self.max_retries:
            logger.error(
                f"ĞŸÑ€ĞµĞ²Ñ‹ÑˆĞµĞ½Ğ¾ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğº ({self.max_retries}). "
                f"ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ÑÑ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {error}"
            )
            raise

        delay = self.base_delay * (2 ** (self.consecutive_errors - 1))
        logger.warning(
            f"ĞÑˆĞ¸Ğ±ĞºĞ° #{self.consecutive_errors}: {error}. ĞŸĞ¾Ğ²Ñ‚Ğ¾Ñ€ Ñ‡ĞµÑ€ĞµĞ· {delay:.1f}s"
        )
        await asyncio.sleep(delay)

    async def reset_errors(self) -> None:
        if self.consecutive_errors > 0:
            logger.debug("Ğ¡Ñ‡ĞµÑ‚Ñ‡Ğ¸Ğº Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº ÑĞ±Ñ€Ğ¾ÑˆĞµĞ½ Ğ¿Ğ¾ÑĞ»Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°")
            self.consecutive_errors = 0

```

### app/utils/validators.py

```python
# app/utils/validators.py

import hashlib
import re


def validate_telegram_url(url: str) -> bool:
    pattern = r"^https?://t\.me/[a-zA-Z0-9_]+/?$"
    return bool(re.match(pattern, url))


def validate_vk_url(url: str) -> bool:
    pattern = r"^https?://vk\.com/(public|club|)[a-zA-Z0-9_]+/?$"
    return bool(re.match(pattern, url))


def extract_telegram_username(url: str) -> str | None:
    match = re.search(r"t\.me/([a-zA-Z0-9_]+)", url)
    return match.group(1) if match else None


def extract_vk_id(url: str) -> str | None:
    match = re.search(r"vk\.com/(public|club|)([a-zA-Z0-9_]+)", url)
    return match.group(2) if match else None


def generate_content_hash(text: str | None, media_urls: list[str] | None = None) -> str:
    content = ""

    if text:
        normalized_text = " ".join(text.split())
        content += normalized_text

    if media_urls:
        content += "|".join(sorted(media_urls))

    return hashlib.sha256(content.encode("utf-8")).hexdigest()


def sanitize_text(text: str | None) -> str | None:
    if not text:
        return None

    text = re.sub(r"\n{3,}", "\n\n", text)
    text = text.strip()

    return text if text else None

```

### pyproject.toml

```toml
[project]
name = "content-aggregator-bot"
version = "0.1.0"
description = "soon..."
readme = "README.md"
requires-python = ">=3.14"
dependencies = [
    "aiogram",
    "aiohttp",
    "aiosqlite",
    "loguru",
    "pydantic",
    "pydantic-settings",
    "python-dotenv",
    "pyyaml",
    "sqlalchemy",
    "telethon",
    "vk-api",
]

[dependency-groups]
dev = ["ruff"]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["app"]

[project.scripts]
bot = "app.__main__:run_main"

```

